{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 13: XPath part 1\n",
    "\n",
    "Over this week and next week we'll be going over XPath, but also discovering more about how to parse over multiple files and do more advanced stuff with lists and nested accumulator patterns.\n",
    "\n",
    "## Readings for this week\n",
    "\n",
    "For new to XML, please start here: https://www.w3schools.com/xml/default.asp.  Read Introduction through Attributes, then stop.  Those who've worked with XML should at least take a skim through those pages and refresh your understanding of the XML lingo.\n",
    "\n",
    "## What is XML?\n",
    "\n",
    "If you truly have zero knowledge of XML, I invite you to start with the a good skim of the [Wikipedia page](https://en.wikipedia.org/wiki/XML) on the subject. Don't pour over it, but it'll provide some important background vocabulary and context.  Anyhow, XML is ruleset for marking up documents in specific ways, and has been extended to a method of storing data in a very structured way.  Instead of having a row/column structure like a CSV file, you can have nested and thus much more complex data storage this way.\n",
    "\n",
    "Much of library metadata is stored in XML marked up documents, and that's the focus of the Metadata in Theory and Practice class offered at the iSchool.  Meanwhile, HTML is another markup language that works very similarly to XML.  Unless the HTML is severely malformed,techniques to extract data out of XML will also be useful for extracting data out of web pages.\n",
    "\n",
    "## What is XPath?\n",
    "\n",
    "XPath (https://en.wikipedia.org/wiki/XPath) is a query lanaguage (a la SQL, kind of) used to describe both locations for items and data extraction for XML documents/data.  This means that you can use it to both locate a specific element within an XML document but it also includes functions to pull out desired values.  Much of the time that's the text of that element, but sometimes you'll want other stuff.\n",
    "\n",
    "XPath is a system that is platform and tool independent, and thus you can actually find tools for it in the Oxygen XML editor, and there are a few other resources.  There are many Python tools that utilize XPath and have functions for applying XPath queries, but we're going to explore one of those.  \n",
    "\n",
    "## Installing lxml\n",
    "\n",
    "For this first week we'll be using some other tools than python for exploring xpath, but it wouldn't hurt to go ahead and get this installed.\n",
    "\n",
    "Your anaconda installation should already have included an installation of lxml.  Should you need it, lxml is a module available from PyPi, which means you can use pip to install it.  Please follow these directions:\n",
    "\n",
    "1. Open up your terminal or command prompt (this is the same as you did when you were testing your anaconda installation at the beginning of the semester.\n",
    "2. Type in `pip install lxml` and press enter.  You should not get an error.\n",
    "3. It should begin a downloading process and not end in a \"failed\" statement.\n",
    "4. Once you're back to the normal command prompt, type in `python` to open up IDLE.  Again, exactly how you did when testing out Anaconda.\n",
    "5. Type in `from lxml import etree` and press enter.  You should not see anything returned.  Let me know if you get an error an what that error is.\n",
    "6. Download a copy of the base script from the assignment and attempt to run it inside of PyCharm.  If you passed step 5 without an error, it should run without a problem.  \n",
    "    * Remember that this script requires that you have the files in a place the script can find them.  By default, it is expecting them to be in a folder a the same level of the script itself.  The script will run and execute with no data if it can't find the files, so a lack of error won't help you.  The start of the program has a statement to print out the file names it finds, so you should see something appear in your ouput.  Printing of an empty list means that it didn't find anything.\n",
    "    \n",
    "    \n",
    "# Xpath tools\n",
    "\n",
    "There are several tools that will run xpath queries.  Oxygen will work on valid xml files, although it tends to complain pretty hard about most common HTML because the internet is the wild west for validity.\n",
    "\n",
    "There are other tools, like XPath Helper in chrome that can work.\n",
    "\n",
    "Also, google sheets has a function called `IMPORTXML(url, xpath)` that will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essential vocabulary\n",
    "\n",
    "No matter which scraping or parsing tool that you use, you will not be able to navigate the documentation or create new things if you don't know the language behind the purpose.\n",
    "\n",
    "Let's take this one example:\n",
    "\n",
    "```XML\n",
    "<a href = \"http://ischool.illinois.edu/\">iSchool</a>\n",
    "```\n",
    "\n",
    "This is how you make a hyperlink in HTML.  The bit between the two tags is what shows up on the website and the bit in quotes after the href is where the link will go when you click it.  \n",
    "\n",
    "HTML can be considered to be a specific form of XML.  Remember that XML is just a set of rules, and HTML is just one of those sets (I think there are purists who would disagree on a few points, because modern web browsers allow you to violate every known rule of XML and still render, but that's not a debate to have here).\n",
    "\n",
    "Here are the essential names that you need to know:\n",
    "\n",
    "\n",
    "* element name:  this is `a`, where you see in the <>.  The element contains all the information that you want.  The <> define where certain parts of the element exist.  Don't worry, we'll get into more of that.\n",
    "* node:  roughly, this is the entire contraption that you see there.  The a element and everything about it and what's in it.\n",
    "* opening tag: this is the `<a>` piece\n",
    "* closing tag:  this is the `</a>` piece\n",
    "* element content or value:  sometimes elements will hold just text, another element, a mix of both, or nothing at all!  The stuff that is between the > and < (so after the opening tag and before the closing tag), is the element's content.\n",
    "* attributes:  these are key/value pairs that appear inside the opening tag.  You can see this is the href.  \n",
    "* attribute name:  the thing on the left side of the =.  Much like dictionaries, all attribue names must be unique inside the opening tag.\n",
    "* attribute value:  the thing on the right side of the =.  This is the URL.  Generally you'll find these in quotes, but not always.\n",
    "\n",
    "Meanwhile, all valid XML must have a single root element that everything belongs inside.  You can see this in proper HTML, which is the `<html>` tag.  Every other element that you see in this website is a descendant element of that root.  Elements (except for the root element) have a parent element.\n",
    "\n",
    "```XML\n",
    "\n",
    "<root>\n",
    "    <middle>\n",
    "        <child>stuff</child>\n",
    "    </middle>\n",
    "</root>\n",
    "```\n",
    "\n",
    "Parent, child, and tree:\n",
    "\n",
    "`root` is the parent of `middle`, and `middle` is the parent of `child`.  Together these make the tree.  \n",
    "\n",
    "When you are constructing XPath queries, you'll need to operationalize the patterns and locations that you see into these sorts of terms.  Once you can do that, you can string together the names of things in the XML tree and XPath punctuation to build up your query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XPath punctuation and syntax\n",
    "\n",
    "The simplest XPath query is a list of elements, separated by `/`, to desribe an exact location in the tree.  For example, in the previous structure, I could access the location of `child` via:\n",
    "\n",
    "`/root/middle/child`\n",
    "\n",
    "This should look very similar to a URL or a file path.  The `/` is used in a similar way.\n",
    "\n",
    "However, sometimes there are multiple elements that you want or you don't need to spefify the full path to that element.  You can use `//` to have the query search at any level of the tree instead of starting at the root.\n",
    "\n",
    "`//child`\n",
    "\n",
    "This query would look for the `child` tag at any level in the tree.\n",
    "\n",
    "There are several basic syntax elements and metacharacters:\n",
    "\n",
    "* an element name needs no other syntax to be to be a reference for an element, as you can see with our references with `child`\n",
    "* `/` look only 1 level deep, so only for immediate children of the element preceeding it\n",
    "* `//` look anywhere in the descendents of the element preceeding it\n",
    "* `.` indicate the current node (you'll usually use this inside of functions)\n",
    "* `..` indicate the parent node of the current element.  You can use this to have it `look` up to a previous element.  For example, \"find this speficic element, but then select the element parent to it\"\n",
    "* `@` this is used before a name to indicate that you are talking about an attribute name instead of an element name.  For example, `@href` for an `a` element.  \n",
    "* `element[position number]`:  index starting at 1, allows you to indicate the \"nth\" instant of that element.  Example, `a[3]` would be the third a found with that query.\n",
    "* `element[logical check]` You can place a variety of functions and other boolean checks inside the `[]`.  There are multiple things you can put in here (https://www.w3schools.com/xml/xsl_functions.asp).\n",
    "* `element[@attribute = 'something']` you can use this to select an element with an attribute that has a specific value\n",
    "\n",
    "Of course, all these things are used to just select the element in question.  From there, you have te extract out what you want.  This is a bit opaque when using a pretty normal xpath tool, but made much more explicit when dealing with things in python.  Particularly with lxml.  You'll only get an element object if you don't select the content that you want.  \n",
    "\n",
    "Generally speaking, there are going to be 2 things you might out of on element:\n",
    "\n",
    "* the attribute value\n",
    "    * you can get this by adding `@attribute` to the end of a query\n",
    "    * example:  `//a/@href`\n",
    "* the element content\n",
    "    * you have to use a spific function at the end of the query to get the text: `text()`  Note the `()` in there, that are required.\n",
    "    * Example:  `//a/text()`\n",
    "    * Remember that `/` will only look one level deep.  If there are additional elements in there, such as bolded text, it will grab everything around it and skip it.  However, you can ask it to grab all text at any level under the element that you have selected.\n",
    "    * Example:  `//a//text()`\n",
    "\n",
    "We'll use all of these in our example below, but it can be helpful to copy these and keep them handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 steps to writing a query\n",
    "\n",
    "This is a very iterative process, but it can be helpful to have at least some place to start.  \n",
    "\n",
    "## 1:  Identify your target\n",
    "\n",
    "You'll either be dealing with an XML file here or you'll want to view source on the website that you're after.  Some websites have proctions put in place to prevent you accessing the content, so there may be oddities.  \n",
    "\n",
    "For websites, copy one of the things you are after and go into the page source.  Search inside the page code to find where it is.  Chrome developer tools (View>Developer>Developer Tools) allows you to navigate the structure in an easier way.\n",
    "\n",
    "Take note of where that content is, what the element is, parent element is, any attributes it has, those attribute values, etc.  These are all clues that you can use to help select the proper content.  Remember that you arent just after the content that you want, you are after the element itself and the things around it.\n",
    "\n",
    "In our case, this content is inside an `a` element that is in a `td` (table data) element in an HTML table.\n",
    "\n",
    "Goal:  be able to operationalize in formal XML vocabulary where the content is located.\n",
    "\n",
    "## 2:  Pick your starting place\n",
    "\n",
    "Often, the first element that you start looking for will determine the approach that you end up having to take.  \n",
    "\n",
    "You have to find a balance that:\n",
    "\n",
    "* selects all the things that you want\n",
    "* not so much other stuff that you have too much noise to clean up\n",
    "\n",
    "There is where yo umust know the structure of what you are dealing with, and where to find this balance. Something broad enough that it gets you started, but not something so broad that it brings in too much or doesn't provide value.  This is sort of where the art form comes in, and an experienced eye can help direct you.\n",
    "\n",
    "Goal:  get as close as possible to your target content without losing any of it in the process.\n",
    "\n",
    "## 3:  Start drilling down\n",
    "\n",
    "Once you have the starting place, you will start adding elements and other selectors after it until all that is left are the things that you want.  You'll drill in closer and closer, being careful to not leave anything that you want behind.\n",
    "\n",
    "There may be situations where you start down a perfectly reasonable path, but with that path there may be no way to uniquely specify what you are after.  This may mean that you need to back up and start from a different place, or sometimes you need to bring the values in to Python proper and use string methods etc to get out what you want.\n",
    "\n",
    "## 4:  Check your work\n",
    "\n",
    "You may have set along several paths to get your anwer, and don't worry, there isn't some mythical place that you must discover.  You are done with the first query you find that holds true across all your cases.  Let's look at these two pieces:\n",
    "\n",
    "1. \"first one\" there's no value in chasing down every path to try and find some perfect solution.  Don't overengineer the details of what you are after if those details don't add anything to what you are trying to get at.\n",
    "2. \"holds true across all your cases\" You may have found a solution to one of your cases, and so you need to test that solution onto all of your data.  This doen imply that you have the capability of doing just that (applying an algorithm on many files or whatever you have) and checking that what you are getting back is what your are after.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worked example\n",
    "\n",
    "Let's take this website:  http://www.j-archive.com/showplayer.php?player_id=11699  This is for a player on Jeopardy who participated in two games.  Our goal is to get the text out about the two games.  Yes, there are only two here in this case, but think bigger.  What if you wanted the data for Ken Jennings (http://j-archive.com/showplayer.php?player_id=1)?  Or wanted it to run over all 11,000 players?\n",
    "\n",
    "This website is PHP, meaning that the data content reported out has a steady structure.\n",
    "\n",
    "## Step 1:  where do we want to start?\n",
    "\n",
    "Well, we know that what we want is within an `a` element. So we can start by just looking for that.\n",
    "\n",
    "`//a`\n",
    "\n",
    "This gives us 12 results, which includes what we want, but a few extra things like the player stats and some of the links in the footer.\n",
    "\n",
    "## Step 2:  Drill down\n",
    "\n",
    "From an element perspective, we've gone as far down as we can get.  At this point we have a choice: \n",
    "\n",
    "1.  Add in a conditional that can uniquely identify the `a` elements that we want from the ones we don't.\n",
    "2.  Back up and try a different starting point.\n",
    "\n",
    "We can use both of these to sucessuflly drill down.\n",
    "\n",
    "### Filtering the `a` elements with the `starts-with()` function\n",
    "\n",
    "Looking at the results, we can tell a few differences in the `a` elements that we want versus the ones that we don't.\n",
    "\n",
    "Here are the element values for all the `a` elements:\n",
    "\n",
    "```\n",
    "[current season]\n",
    "[last season]\n",
    "[all seasons]\n",
    "[prizes]\n",
    "[wagering calculator]\n",
    "[help]\n",
    "#7614, aired 2017-10-19\n",
    "#7613, aired 2017-10-18\n",
    "[player statistics]\n",
    "Jeopardy!\n",
    "JBoard.tv\n",
    "```\n",
    "\n",
    "The ones that we want have dates, but also all start with the `#` character.  We can use the `starts-with()` xpath function to filter these out.\n",
    "\n",
    "Here's the syntax:  `starts-with(node, text)`\n",
    "\n",
    "That node trick is a weird one.  There are other things you can do, but for the most part you are going to provide one of two things:\n",
    "\n",
    "1. `starts-with(., \"stuff\")` to check the current node\n",
    "2. `starts-with(@attribute, \"stuff\")` to check that attributes value\n",
    "\n",
    "Each of these things are in relation to the element that you call the function into. The function call goes into the `[]` after the element in your selector.  Again, all this is easier to see with an example.\n",
    "\n",
    "So we know that we're looking for \"#\" at the start text value, and that it's for the element text itself.  This meants that we want:\n",
    "\n",
    "* to call the function on the `a` tag, so:  `a[starts-with(...)]`\n",
    "* to reference the current node (the text of the `a` element itleslf), so:  `.` (this shouldn't be in quotes because it is a literal part of the syntax).\n",
    "* and look for #, so: `\"#\"`\n",
    "\n",
    "Putting all that together, we can use:\n",
    "\n",
    "`//a[starts-with(., \"#\")]`\n",
    "\n",
    "### Filtering the a with the `contains()` function\n",
    "\n",
    "We could have also checked the contents of the URL. Looking closely, we can see that they have a URL with \"game_id\" in it.  The `contains()` function works similarly to `starts-with()`.  You call it on the element you want to test, then provide it the thing to look at, and what the content is.\n",
    "\n",
    "* we want to call it on our `a` element, so:  `a[contains(...)]`\n",
    "* we want it to look in the `href` centent, so:  `@href` (again, no quotes here)\n",
    "* we want it to look for \"game_id\", so `\"game_id\"`\n",
    "\n",
    "Putting this all together, we get:\n",
    "\n",
    "`//a[contains(@href, \"game_id\")]`\n",
    "\n",
    "### Step 3:  testing it on more examples\n",
    "\n",
    "Great!  Now, this works for our small example. But this website isn't exactly as steady as it seems.  We can try this on the Ken Jennings site.  Ahh, there are links with this same format all over the place in the free text.  So this is being explcit about what it's looking for, but not specific about the location.  \n",
    "\n",
    "This is the time to back up.\n",
    "\n",
    "### aaaaand Backing up and adding more location information\n",
    "\n",
    "We know that the `a` elements we want are in a `td` element.  We can try adding that in.\n",
    "\n",
    "`//td/a[starts-with(., \"#\")]`\n",
    "\n",
    "This still works on our smaller example, let's try it on Ken.\n",
    "\n",
    "And that's done it!  We've added just enough location detail to uniquely separate out what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting from the other end\n",
    "\n",
    "In the previous example, we started at the shallowest levels possible.  We started right at the `a` and had to break into testing the content to differentiate.  However, we could have started from an element further away from the content and drilled down more structurally.  Had we done this, we could have avoided the function entirely.\n",
    "\n",
    "We know that the things we want are in a table.  So let's look for the tables.\n",
    "\n",
    "`//table`\n",
    "\n",
    "This gives us 2 tables.  One has some other stuff, one has the stuff that we want.  We can put a position number in the brackets to select one that we want.\n",
    "\n",
    "`//table[2]`\n",
    "\n",
    "This gives us the game table. Now we can drill into the table structure.  This requires a bit of the HTML know how, but you can also just look in the structure and copy what you see.\n",
    "\n",
    "We know what we want is in a td:\n",
    "\n",
    "`//table[2]/tbody/tr/td`\n",
    "\n",
    "This is giving us all the td cells.  The data that we want is in the first td of teach tr.  So we could use a position call on the td to say that we want the first one.\n",
    "\n",
    "`//table[2]/tbody/tr/td[1]`\n",
    "\n",
    "So it looks like we've gotten what we want, and we've got the node.  This would be what we would need to do if the content we want wasn't in an `a` element.  Because it is, we can say \"the a element in the tds\".\n",
    "\n",
    "`//table[2]/tbody/tr/td/a`\n",
    "\n",
    "## exploiting a CSS artifact\n",
    "\n",
    "Sometimes the CSS of a website can give a lot away allow you to be much more specific than you might originally have thought of.  Unfortunately, this kind of CSS exploit usually doesn't reveal itself to you unless you are digging through the row HTML.  Some websites are structured such that many of the elements have class namee or other style values that you can exploit.  \n",
    "\n",
    "The cool thing is that all the CSS codes added in are added as attribute values, and we know how to look those up with XPathe.  \n",
    "\n",
    "Taking another look at the `a` element, there's nothing juicy happening there. However, looking up one level at the tds that have our game info, we can see that they have `style = \"width:140px\"`.  This sets the cell to a fixed width, but also gives us something that we can look up.  You can do a search within the source text for 140px and see that it only appears in the tds that have the data we want.  So we can select those explicitly.\n",
    "\n",
    "`//td[@style = \"width:140px\"]/a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we've got what we've come for\n",
    "\n",
    "Let's not forget that so far we've only selected the node that we want.  None of the queries that we've run would have given us the text content that we wanted.\n",
    "\n",
    "## Grabbing the text\n",
    "\n",
    "To get the element text out of the element, we can add `text()` to the end our selection statement. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How does that apply to this?\n",
    "\n",
    "There is a notion of 1 to many in databases, which is actually quite a common feature in data.  For example, a single book may have many authors.  A class has many students.  A faculty member has many affiliations.  And so on.  XML is quite good at representing these relationships because it can nest things.  So let's break out some actual xml.  \n",
    "\n",
    "``` XML\n",
    "<book>\n",
    "    <author>Human, A.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\n",
    "```\n",
    "\n",
    "This is a pretty clear case.  There's one book and one author for that book.  In this case, something like `\"//book/author/text()\"` would be sufficient for tracking down that author's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Human, A.']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "xml = \"\"\"<book>\n",
    "    <author>Human, A.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\"\"\"\n",
    "\n",
    "tree = etree.fromstring(xml)\n",
    "print(tree.xpath('//book/author/text()'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And exactly that!  **But** let's take a closer look at what just happened with this result.  Note that I didn't just get a string of the thing that I wanted.  I got a list with a single string within it.  This can tell you that the `xpath()` function is well prepared for getting multiple results.  \n",
    "\n",
    "The fact that my data may have multiple values for these items means that I need to completely change my approach for getting this data out.  We've used SQL last week that would print back to us a tbale of results.  We, as humans, were planning on processing that. We didn't have to care.  The functions we wanted to apply to each column were ready to handle instances of zero, one, or many results.  SQL just handles it.\n",
    "\n",
    "But this is a different world, where we need to write lower level code.  So you, as the programmer, need to deal with that kind of thing.  Let's practice a primary and secondary loop pattern over this sort of returned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Human, A.\n",
      "23 Human, A.\n",
      "23 Human, Not.\n"
     ]
    }
   ],
   "source": [
    "xml = [\"\"\"<book>\n",
    "    <book_id>42</book_id>\n",
    "    <author>Human, A.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\"\"\",\n",
    "\n",
    "\"\"\"<book>\n",
    "    <book_id>23</book_id>\n",
    "    <author>Human, A.</author>\n",
    "    <author>Human, Not.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\"\"\"]\n",
    "\n",
    "# so we've got multiple chunks of xml here\n",
    "# we know that book_id will only happen once (because I'm saying so here)\n",
    "# but we may have multiple authors\n",
    "\n",
    "for data_chunk in xml:\n",
    "    tree = etree.fromstring(data_chunk)\n",
    "    author_list = tree.xpath('//book/author/text()')\n",
    "    book_id_list = tree.xpath('//book/book_id/text()')\n",
    "    if len(book_id_list) != 1:\n",
    "        print(\"Too many book_id values, skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        book_id = book_id_list[0]\n",
    "    for author in author_list:\n",
    "        print(book_id, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This looks pretty good because all the values that I'm getting back are all strings.  All those lists are gone.  This means that the results I'm spitting out from these loops are primed and ready to be written out to a file.  No futher processing.\n",
    "\n",
    "Also note that it worked just fine when I had a list of one item.  \n",
    "\n",
    "Had we not used this primary/secondary patter, we would have ended up with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 ['Human, A.']\n",
      "23 ['Human, A.', 'Human, Not.']\n"
     ]
    }
   ],
   "source": [
    "for data_chunk in xml:\n",
    "    tree = etree.fromstring(data_chunk)\n",
    "    author_list = tree.xpath('//book/author/text()')\n",
    "    book_id_list = tree.xpath('//book/book_id/text()')\n",
    "    if len(book_id_list) != 1:\n",
    "        print(\"Too many book_id values, skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        book_id = book_id_list[0]\n",
    "    print(book_id, author_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could make this work by running a join on those lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 Human, A.\n",
      "23 Human, A.;Human, Not.\n"
     ]
    }
   ],
   "source": [
    "for data_chunk in xml:\n",
    "    tree = etree.fromstring(data_chunk)\n",
    "    author_list = tree.xpath('//book/author/text()')\n",
    "    book_id_list = tree.xpath('//book/book_id/text()')\n",
    "    if len(book_id_list) != 1:\n",
    "        print(\"Too many book_id values, skipping\")\n",
    "        continue\n",
    "    else:\n",
    "        book_id = book_id_list[0]\n",
    "    print(book_id, \";\".join(author_list)) # look here for the change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your data design you may want:\n",
    "\n",
    "1. To have any multiple values represented in separate rows\n",
    "    * So you'd need to use the primary/secondary loop pattern\n",
    "2. Having any multiple values in a single cell is fine\n",
    "    * Then you can do the \"delim\".join(stuff) pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Conclusion...\n",
    "\n",
    "So now that we have a basis of strategy and tool, we can explore more about xpath itself in our next lesson.  Look next to week 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
