{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: lists and subloops\n",
    "\n",
    "Sequences have order, meaning that individual items have specific positions.  You can use those positions:\n",
    "\n",
    "* as their explicit meaning (so the numbers are directily meaningful)\n",
    "* as a transformed meaning (so you can add 1 or do something else to the position number to make it meaningful)\n",
    "* with a referenced meaning (such that you can use the position number to look up the meaning).\n",
    "\n",
    "These items can also be individually manipulated.  Once referenced, they can be stored in memory, placed in another structure, and used as a source for further data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem statement\n",
    "\n",
    "Given a data file of data repository records and extract the number of downloads.  Calculate the total number of dataset downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll be discussing reading in files later!\n",
    "\n",
    "f = open('report.txt', 'r')\n",
    "\n",
    "full_text = f.read()\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here's a small snippet we can see in one screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = \"\"\"Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V1\n",
    "Downloads: 9 (2017-08-30 to 2017-09-13 )\n",
    "-----\n",
    "\n",
    "Park, Jungsik; Le, Brian; Sklenar, Joseph; Chern, Gia-wei; Watts, Justin; Schiffer, Peter (2017): Magnetic response of brickwork artificial spin ice. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-1528275_V1\n",
    "Funder: U.S. Department of Energy (DOE), Grant: DE-SC0010778\n",
    "Downloads: 10 (2017-09-08 to 2017-09-13 )\n",
    "-----\n",
    "\n",
    "Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2\n",
    "Downloads: 6 (2017-09-06 to 2017-09-13 )\n",
    "-----\n",
    "\n",
    "Christensen, Sarah; Molloy, Erin K.; Vachaspati, Pranjal; Warnow, Tandy (2017): Datasets from the study: Optimal completion of incomplete gene trees in polynomial time using OCTAL. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-8402610_V1\n",
    "Funder: U.S. National Science Foundation (NSF), Grant: CCF-1535977\n",
    "Funder: U.S. National Science Foundation (NSF), Grant: DGE-1144245\n",
    "Downloads: 47 (2017-06-15 to 2017-09-13 )\n",
    "-----\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's our structure here?\n",
    "\n",
    "We've got data on datasets here, but this isn't a tabular data file.  We can't open it up in excel or directly do computations on it, yet.  We need to transform it into something with a standard sturucture for analysis.\n",
    "\n",
    "A few things to note:\n",
    "\n",
    "* the number of lines per entry is variable, so we can't exploit a steady mathematical structure like we did with the Raven last week.\n",
    "* even if variable, we can see that the lines inside each entry are meaningful \n",
    "* each line has a field label followed by a : and then content\n",
    "* some of these fields have multiple entries (so multiple lines with the same field entry)\n",
    "* some of the line content has multiple values\n",
    "* the string \"-----\" appears (to appear!) between each entry\n",
    "\n",
    "# What's our data granularity?\n",
    "\n",
    "Last week we explored a poem and found that our unit of analysis of interest are the individual lines.  That made it easy because python knows about lines and has functions designed to easily interact with them.  In this case, our individual data entities records about the dataset.  This sort of thing, especially with the variability in size, is not something that python is able to directly interact with.  Our recourse for this issue is to use the tools inside of python to encode these chunks as individual data entries.  Once we have the individual records out we can operate on them independently and exract the information out.\n",
    "\n",
    "This pattern of breaking the data apart so that we can apply broader (easier) methods of splitting individual data points out will be a common one.\n",
    "\n",
    "Let's take a moment to consider the Raven again.  Say that we want to know about the words in each stanza.  We could use regular `.split()` on the entire poem and get all the words.  We'd have the granularity that we want (the words) but the membership information would then be gone.\n",
    "\n",
    "Recall our basic for loop over lines through the poem:  it allows us to isolate each line at a time such that we can manupulate or take measurements from that line and infer that those measurements we get belong to that line because it is the one we are looping over at the moment.\n",
    "\n",
    "Our example of why using the `range(0, len(raven_lines), 7)` function to make the position numbers and look up the line versus just doing a list slice (`::7`) gave us the same content back (the first line of each stanza), but using the list slicing method lost the line number information in the process.  That origin information could not be derived back from the individual line itself, and thus we depend on our iterable variable within the `range` loop to represent that component metadata about the line.\n",
    "\n",
    "Unlike our pattern where we used `range` to generate the line numbers, the content (the numbers) that we generated with `range` wasn't directly related to our original content.  We used a known pattern to (correctly!) generate postiton numbers.  So there was a certain trust that we had to put into place to make the things work.\n",
    "\n",
    "This time around we are splitting our data into chunks so that we can individually act on the data inside of it.  This means that instead of getting out all the lines that have the funder information and doing something fancy to figure out which chunk it was from, we can take out all the chunks and then get the funder lines from there.  Becuase we are isolating the data records from eachother, we can use a pretty unfancy method of getting out the lines that we want.  \n",
    "\n",
    "For example, the last line of each record is the download count for that dataset.  That location rule would be impossible to use if we weren't isolating each chunk.\n",
    "\n",
    "So to answer our question:  we have several granularities.\n",
    "\n",
    "1. Each data record\n",
    "2. Each line\n",
    "3. Each data point in each line\n",
    "\n",
    "# What's the magic word that we see in that list?\n",
    "\n",
    "**`each`**\n",
    "\n",
    "We aren't going to tackle a triple nested loop to start with, but we need to start somewhere.  Let's give ourselves a little to do list:\n",
    "\n",
    "1. Get all the data records\n",
    "2. For each record, get the lines\n",
    "3. For each line of interest, get the data of interest\n",
    "\n",
    "Don't worry, we're going to do this one at a time.  We won't actually need to do a triple nested loop becuase we can store our intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1:  Get the records\n",
    "\n",
    "Not shockingly, we're going to start with `.split()`.  Remember that we need two things for this:\n",
    "\n",
    "1.  A string to split apart\n",
    "    * Got this covered:  `original`\n",
    "2.  Something in that string to split it apart on\n",
    "    * We have a good theory here: `-----` but we need to confirm\n",
    "    \n",
    "We can visually inspect our file and see that this appears to be between each record.  Not only that, we can look all the way to the end and see that it isn't just between the file but it appears at the end of each record.  So there isn't one before and there is one at the end, meaning that we can expect to see the appearance of 56 instances (so one for every expected record).\n",
    "\n",
    "We can do a quick string method to count how many times it appears in the file.  We'll try it first on our small sample to see it working, and then we'll deploy it onto the whole document that we have stored in memory.\n",
    "\n",
    "We can visually inspect our sample to see that there are 4 entries, so we can expect (hope?) to see a result of 4 when we run our candidate delimiter through the string function that counts how many appearances it makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(sample.count(\"-----\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we can see that we found the expected number of instances in our sample.  Let's try it on our full version.  Remember that we are hoping to see 56."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "print(full_text.count('-----'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay!  Now we can see what the results are of running this through `.split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 records\n",
      "['Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V1\\nDownloads: 9 (2017-08-30 to 2017-09-13 )\\n', '\\n\\nPark, Jungsik; Le, Brian; Sklenar, Joseph; Chern, Gia-wei; Watts, Justin; Schiffer, Peter (2017): Magnetic response of brickwork artificial spin ice. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-1528275_V1\\nFunder: U.S. Department of Energy (DOE), Grant: DE-SC0010778\\nDownloads: 10 (2017-09-08 to 2017-09-13 )\\n', '\\n\\nKozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2\\nDownloads: 6 (2017-09-06 to 2017-09-13 )\\n', '\\n\\nChristensen, Sarah; Molloy, Erin K.; Vachaspati, Pranjal; Warnow, Tandy (2017): Datasets from the study: Optimal completion of incomplete gene trees in polynomial time using OCTAL. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-8402610_V1\\nFunder: U.S. National Science Foundation (NSF), Grant: CCF-1535977\\nFunder: U.S. National Science Foundation (NSF), Grant: DGE-1144245\\nDownloads: 47 (2017-06-15 to 2017-09-13 )\\n', '']\n"
     ]
    }
   ],
   "source": [
    "sample_split = sample.split('-----')\n",
    "\n",
    "print(\"There are\", len(sample_split), \"records\")\n",
    "\n",
    "print(sample_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That length of 5 is a little concerning, but we can take a look and see that the last element is an empty string.  Sometimes this happens when the string we are splitting on appears at the end.  As you can see in the below example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', '']\n"
     ]
    }
   ],
   "source": [
    "print('a-b-c-d-'.split(\"-\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our split has worked, but as usual there's a little more fussing we can do to make it better.  This is a good example of a situation where you won't know exactly what you'll need to do until you get the contents loaded and start working with it.\n",
    "\n",
    "Look at the the sections in the list where the strings should be separated.  Here's a snippet of what I want you to see:\n",
    "\n",
    "`2017-09-13 )`**`\\n', '\\n\\n`**`Christensen,`\n",
    "\n",
    "We haven't mentioned it before, but we've been passing a string with multiple characters in it to split and it has been using it as a single item to split on.  This meann that we can add more to the string that we are passing it and see how what changes things.  From this example, we can see that there are newline characters (`\\n`) surrounding the delimiter, 1 before and 2 after.  If we look closer at the actual file we can see thse characters in action.  The `-----` appears on its own line (so that's the 1 before newline), and there is an extra empty line just below it (so that's the 2 after).  We can try including that in our split.  This change may provide two impacts:  it'll clean up the results a bit (we could always use `.strip()` on them, so that wasn't really a concern.  But it may also get rid of that trailing empty string in our results.\n",
    "\n",
    "So I'm going to copy over the code for our previous example and just add those characters in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 records\n",
      "['Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V1\\nDownloads: 9 (2017-08-30 to 2017-09-13 )', 'Park, Jungsik; Le, Brian; Sklenar, Joseph; Chern, Gia-wei; Watts, Justin; Schiffer, Peter (2017): Magnetic response of brickwork artificial spin ice. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-1528275_V1\\nFunder: U.S. Department of Energy (DOE), Grant: DE-SC0010778\\nDownloads: 10 (2017-09-08 to 2017-09-13 )', 'Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2\\nDownloads: 6 (2017-09-06 to 2017-09-13 )', 'Christensen, Sarah; Molloy, Erin K.; Vachaspati, Pranjal; Warnow, Tandy (2017): Datasets from the study: Optimal completion of incomplete gene trees in polynomial time using OCTAL. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-8402610_V1\\nFunder: U.S. National Science Foundation (NSF), Grant: CCF-1535977\\nFunder: U.S. National Science Foundation (NSF), Grant: DGE-1144245\\nDownloads: 47 (2017-06-15 to 2017-09-13 )\\n-----']\n"
     ]
    }
   ],
   "source": [
    "sample_split = sample.split('\\n-----\\n\\n')\n",
    "\n",
    "print(\"There are\", len(sample_split), \"records\")\n",
    "\n",
    "print(sample_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of information happening in this readout, so we'll have to look closely to see what's going on.  Looking between the elements, we can see that the breaks are pretty clean, but the last element is still holding a copy of our delimiter.  This is because it has the `\\n-----` but is missing the final `\\n\\n` thus is not removed.\n",
    "\n",
    "We can play with removing some of the new lines in the split and see if that helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 records\n",
      "['Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V1\\nDownloads: 9 (2017-08-30 to 2017-09-13 )', '\\n\\nPark, Jungsik; Le, Brian; Sklenar, Joseph; Chern, Gia-wei; Watts, Justin; Schiffer, Peter (2017): Magnetic response of brickwork artificial spin ice. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-1528275_V1\\nFunder: U.S. Department of Energy (DOE), Grant: DE-SC0010778\\nDownloads: 10 (2017-09-08 to 2017-09-13 )', '\\n\\nKozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2\\nDownloads: 6 (2017-09-06 to 2017-09-13 )', '\\n\\nChristensen, Sarah; Molloy, Erin K.; Vachaspati, Pranjal; Warnow, Tandy (2017): Datasets from the study: Optimal completion of incomplete gene trees in polynomial time using OCTAL. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-8402610_V1\\nFunder: U.S. National Science Foundation (NSF), Grant: CCF-1535977\\nFunder: U.S. National Science Foundation (NSF), Grant: DGE-1144245\\nDownloads: 47 (2017-06-15 to 2017-09-13 )', '']\n"
     ]
    }
   ],
   "source": [
    "sample_split = sample.split('\\n-----')\n",
    "\n",
    "print(\"There are\", len(sample_split), \"records\")\n",
    "\n",
    "print(sample_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the trailing two `\\n` characters allows the delimiter to go away, but now we have that empty line appearing again.  \n",
    "\n",
    "We have to choose:  do we want to deal with removing the `-----` at the end or have to strip the whitespace off and remove the last empty string.  We could also alter our original text to fix this last delimiter to look like the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 records\n",
      "['Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V1\\nDownloads: 9 (2017-08-30 to 2017-09-13 )', 'Park, Jungsik; Le, Brian; Sklenar, Joseph; Chern, Gia-wei; Watts, Justin; Schiffer, Peter (2017): Magnetic response of brickwork artificial spin ice. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-1528275_V1\\nFunder: U.S. Department of Energy (DOE), Grant: DE-SC0010778\\nDownloads: 10 (2017-09-08 to 2017-09-13 )', 'Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2\\nDownloads: 6 (2017-09-06 to 2017-09-13 )', 'Christensen, Sarah; Molloy, Erin K.; Vachaspati, Pranjal; Warnow, Tandy (2017): Datasets from the study: Optimal completion of incomplete gene trees in polynomial time using OCTAL. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-8402610_V1\\nFunder: U.S. National Science Foundation (NSF), Grant: CCF-1535977\\nFunder: U.S. National Science Foundation (NSF), Grant: DGE-1144245\\nDownloads: 47 (2017-06-15 to 2017-09-13 )', '']\n"
     ]
    }
   ],
   "source": [
    "sample_fixed = sample + \"\\n\\n\"\n",
    "\n",
    "sample_split = sample_fixed.split('\\n-----\\n\\n')\n",
    "\n",
    "print(\"There are\", len(sample_split), \"records\")\n",
    "\n",
    "print(sample_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the extra newlines fixes the split, but we've got that extra string in there.  We could always remove tho last element, so long as we are sure that the last item is empty.  That kind of check will be something we can do when we start with boolean logic and decision structures.  For now, we can explore an alternative path.\n",
    "\n",
    "We could also try to remove it, but the content is a subset of our larger delimeter, so removing just what it is would remove all our delimeters.\n",
    "\n",
    "We could also remove the last 5 characters from the string, which will do the same.\n",
    "\n",
    "For the sake of practicing our list methods, we're going to explore `.pop()`.  With more advanced tests we could put in a check that it really is a string of length 0, but for now we can at least visually inspect what we are removing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_split.pop(-1) # we want the last one, so our -1 friend will come back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.pop()` will mutate our original list, so you see how there is no assignment statement happening here.  In fact, if we try to reassign our list to the results of `pop` we will have erased all the data we want with the data that we are removing. \n",
    "\n",
    "We can see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 records\n",
      "['Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V1\\nDownloads: 9 (2017-08-30 to 2017-09-13 )', 'Park, Jungsik; Le, Brian; Sklenar, Joseph; Chern, Gia-wei; Watts, Justin; Schiffer, Peter (2017): Magnetic response of brickwork artificial spin ice. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-1528275_V1\\nFunder: U.S. Department of Energy (DOE), Grant: DE-SC0010778\\nDownloads: 10 (2017-09-08 to 2017-09-13 )', 'Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2\\nDownloads: 6 (2017-09-06 to 2017-09-13 )', 'Christensen, Sarah; Molloy, Erin K.; Vachaspati, Pranjal; Warnow, Tandy (2017): Datasets from the study: Optimal completion of incomplete gene trees in polynomial time using OCTAL. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-8402610_V1\\nFunder: U.S. National Science Foundation (NSF), Grant: CCF-1535977\\nFunder: U.S. National Science Foundation (NSF), Grant: DGE-1144245\\nDownloads: 47 (2017-06-15 to 2017-09-13 )', '']\n",
      "and now our data is: \n"
     ]
    }
   ],
   "source": [
    "sample_fixed = sample + \"\\n\\n\"\n",
    "\n",
    "sample_split = sample_fixed.split('\\n-----\\n\\n')\n",
    "\n",
    "print(\"There are\", len(sample_split), \"records\")\n",
    "\n",
    "print(sample_split)\n",
    "\n",
    "sample_split = sample_split.pop(-1)\n",
    "\n",
    "print(\"and now our data is:\", sample_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 records\n",
      "['Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V1\\nDownloads: 9 (2017-08-30 to 2017-09-13 )', 'Park, Jungsik; Le, Brian; Sklenar, Joseph; Chern, Gia-wei; Watts, Justin; Schiffer, Peter (2017): Magnetic response of brickwork artificial spin ice. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-1528275_V1\\nFunder: U.S. Department of Energy (DOE), Grant: DE-SC0010778\\nDownloads: 10 (2017-09-08 to 2017-09-13 )', 'Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2\\nDownloads: 6 (2017-09-06 to 2017-09-13 )', 'Christensen, Sarah; Molloy, Erin K.; Vachaspati, Pranjal; Warnow, Tandy (2017): Datasets from the study: Optimal completion of incomplete gene trees in polynomial time using OCTAL. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-8402610_V1\\nFunder: U.S. National Science Foundation (NSF), Grant: CCF-1535977\\nFunder: U.S. National Science Foundation (NSF), Grant: DGE-1144245\\nDownloads: 47 (2017-06-15 to 2017-09-13 )']\n",
      "There are now 4 records\n"
     ]
    }
   ],
   "source": [
    "sample_fixed = sample + \"\\n\\n\"\n",
    "\n",
    "sample_split = sample_fixed.split('\\n-----\\n\\n')\n",
    "\n",
    "print(\"There are\", len(sample_split), \"records\")\n",
    "\n",
    "sample_split.pop(-1)\n",
    "\n",
    "print(sample_split)\n",
    "\n",
    "print(\"There are now\", len(sample_split), \"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: split the records apart\n",
    "\n",
    "So let's back up and consider what we have done and still need to do.\n",
    "\n",
    "We've got a list of our individual records.  Next step:  go over each record and get the line with the downloads data.\n",
    "\n",
    "As we have explored, we know that the downloads line is the last line of each record (now do you see why I gave this problem statement?)\n",
    "\n",
    "Let's grab a single record to play with and get a proof of concept going.  Once we're happy with how we are splitting the record up, then we can integrate that into a for loop.  We know that we want the lines out, which we've already explored how we do that with a `str.split('\\n')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2\n",
      "Downloads: 6 (2017-09-06 to 2017-09-13 )\n"
     ]
    }
   ],
   "source": [
    "print(sample_split[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2', 'Downloads: 6 (2017-09-06 to 2017-09-13 )']\n"
     ]
    }
   ],
   "source": [
    "print(sample_split[2].split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a smaller record, but we can see that we have the citation as one element, then the downloads element is indeed the last one.\n",
    "\n",
    "This seems good enough to deploy on our entire sample.  Remember that we should start small and just print out the basics first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V1', 'Downloads: 9 (2017-08-30 to 2017-09-13 )']\n",
      "['Park, Jungsik; Le, Brian; Sklenar, Joseph; Chern, Gia-wei; Watts, Justin; Schiffer, Peter (2017): Magnetic response of brickwork artificial spin ice. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-1528275_V1', 'Funder: U.S. Department of Energy (DOE), Grant: DE-SC0010778', 'Downloads: 10 (2017-09-08 to 2017-09-13 )']\n",
      "['Kozuch, Laura; Walker, Karen; Marquardt, William (2017): Modern sinistral whelk spire angles, genus Busycon . University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-2031816_V2', 'Downloads: 6 (2017-09-06 to 2017-09-13 )']\n",
      "['Christensen, Sarah; Molloy, Erin K.; Vachaspati, Pranjal; Warnow, Tandy (2017): Datasets from the study: Optimal completion of incomplete gene trees in polynomial time using OCTAL. University of Illinois at Urbana-Champaign. https://doi.org/10.13012/B2IDB-8402610_V1', 'Funder: U.S. National Science Foundation (NSF), Grant: CCF-1535977', 'Funder: U.S. National Science Foundation (NSF), Grant: DGE-1144245', 'Downloads: 47 (2017-06-15 to 2017-09-13 )']\n"
     ]
    }
   ],
   "source": [
    "for record in sample_split:\n",
    "    print(record.split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, but how can we tell if the downloads line is indeed the last line of each?  We could just print out the lasti line of each record and visually inspect that each line starts with downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloads: 9 (2017-08-30 to 2017-09-13 )\n",
      "Downloads: 10 (2017-09-08 to 2017-09-13 )\n",
      "Downloads: 6 (2017-09-06 to 2017-09-13 )\n",
      "Downloads: 47 (2017-06-15 to 2017-09-13 )\n"
     ]
    }
   ],
   "source": [
    "for record in sample_split:\n",
    "    record_split = record.split('\\n')\n",
    "    print(record_split[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4 records and now we have 4 download lines.  So this step seems to be taken care of and now this seems to be a good time to test this on all of our data.  Let's also go ahead and combine all these things together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 records\n",
      "There are now 56 records\n"
     ]
    }
   ],
   "source": [
    "full_text_fixed = full_text + \"\\n\\n\"\n",
    "\n",
    "full_text_fixed_split = full_text_fixed.split('\\n-----\\n\\n')\n",
    "\n",
    "print(\"There are\", len(full_text_fixed_split), \"records\")\n",
    "\n",
    "full_text_fixed_split.pop(-1)\n",
    "\n",
    "print(\"There are now\", len(full_text_fixed_split), \"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good!  We have 56 records.  Lets start looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloads: 9 (2017-08-30 to 2017-09-13 )\n",
      "Downloads: 10 (2017-09-08 to 2017-09-13 )\n",
      "Downloads: 6 (2017-09-06 to 2017-09-13 )\n",
      "Downloads: 47 (2017-06-15 to 2017-09-13 )\n",
      "Downloads: 99 (2016-12-18 to 2017-09-13 )\n",
      "Downloads: 3 (2017-12-12 to 2017-09-13 )\n",
      "Downloads: 30 (2016-12-12 to 2017-09-13 )\n",
      "Downloads: 42 (2016-12-12 to 2017-09-13 )\n",
      "Downloads: 93 (2016-12-12 to 2017-09-13 )\n",
      "Downloads: 31 (2016-12-12 to 2017-09-13 )\n",
      "Downloads: 50 (2016-12-12 to 2017-09-13 )\n",
      "Downloads: 12 (2017-08-11 to 2017-09-13 )\n",
      "Downloads: 0 (2017-08-21 to 2017-09-13 )\n",
      "Downloads: 99 (2017-07-29 to 2017-09-13 )\n",
      "Downloads: 931 (2017-06-28 to 2017-09-13 )\n",
      "Downloads: 28 (2017-06-16 to 2017-09-13 )\n",
      "Downloads: 26 (2017-06-16 to 2017-09-13 )\n",
      "Downloads: 28 (2017-06-16 to 2017-09-13 )\n",
      "Downloads: 40 (2017-06-01 to 2017-09-13 )\n",
      "Downloads: 68 (2017-06-01 to 2017-09-13 )\n",
      "Downloads: 18 (2017-05-01 to 2017-09-13 )\n",
      "Downloads: 41 (2017-05-31 to 2017-09-13 )\n",
      "Downloads: 516 (2016-06-23 to 2017-09-13 )\n",
      "Downloads: 72 (2017-05-22 to 2017-09-13 )\n",
      "Downloads: 82 (2017-03-07 to 2017-09-13 )\n",
      "Downloads: 37 (2017-03-07 to 2017-09-13 )\n",
      "Downloads: 1634 (2016-05-19 to 2017-09-13 )\n",
      "Downloads: 99 (2016-06-23 to 2017-09-13 )\n",
      "Downloads: 110 (2016-05-26 to 2017-09-13 )\n",
      "Downloads: 312 (2017-03-08 to 2017-09-13 )\n",
      "Downloads: 132 (2017-03-02 to 2017-09-13 )\n",
      "Downloads: 78 (2017-02-28 to 2017-09-13 )\n",
      "Downloads: 46 (2017-02-23 to 2017-09-13 )\n",
      "Downloads: 140 (2017-02-21 to 2017-09-13 )\n",
      "Downloads: 84 (2017-02-21 to 2017-09-13 )\n",
      "Downloads: 424 (2017-01-06 to 2017-09-13 )\n",
      "Downloads: 269 (2016-12-20 to 2017-09-13 )\n",
      "Downloads: 212 (2016-12-19 to 2017-09-13 )\n",
      "Downloads: 237 (2016-12-14 to 2017-09-13 )\n",
      "Downloads: 98 (2016-12-14 to 2017-09-13 )\n",
      "Downloads: 207 (2016-12-14 to 2017-09-13 )\n",
      "Downloads: 193 (2016-12-14 to 2017-09-13 )\n",
      "Downloads: 200 (2016-12-14 to 2017-09-13 )\n",
      "Downloads: 403 (2016-12-14 to 2017-09-13 )\n",
      "Downloads: 283 (2016-12-14 to 2017-09-13 )\n",
      "Downloads: 336 (2016-12-13 to 2017-09-13 )\n",
      "Downloads: 55 (2016-12-02 to 2017-09-13 )\n",
      "Downloads: 69 (2016-11-30 to 2017-09-13 )\n",
      "Downloads: 163 (2016-11-28 to 2017-09-13 )\n",
      "Downloads: 132 (2016-06-06 to 2017-09-13 )\n",
      "Downloads: 51 (2016-08-16 to 2017-09-13 )\n",
      "Downloads: 70 (2016-08-18 to 2017-09-13 )\n",
      "Downloads: 250 (2016-08-02 to 2017-09-13 )\n",
      "Downloads: 913 (2016-07-22 to 2017-09-13 )\n",
      "Downloads: 130 (2016-05-16 to 2017-09-13 )\n",
      "Downloads: 118 (2016-06-23 to 2017-09-13 )\n"
     ]
    }
   ],
   "source": [
    "for record in full_text_fixed_split:\n",
    "    record_split = record.split('\\n')\n",
    "    print(record_split[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of the results says that we've got this part done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: get the downloads number\n",
    "\n",
    "At this point we've got a good set of results. We've isolated our records and inside each record isolated each line.  With those lines now accessible via position number, we can isolate the last line of the record, which is the line with the data that we want.\n",
    "\n",
    "So let's now consider each line and sort out a way to get those download numbers out.  We've got a string in here, but our granularity is at the level of the word.  While we don't have just words in here, we've got stuff sepapated by white space.  Instead of a `-----` or `\\n` delimiter, we have a single space.\n",
    "\n",
    "Back once again with our friend `.split()`.  But what do we use in this case?  We care about white spaces, which happens te be the default for `.split()`.  Let's just copy one of these lines in and play with splitting the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Downloads:', '118', '(2016-06-23', 'to', '2017-09-13', ')']\n"
     ]
    }
   ],
   "source": [
    "line = \"Downloads: 118 (2016-06-23 to 2017-09-13 )\"\n",
    "\n",
    "print(line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to have done a part of the job.  We've split our line into a series of elements, one of which is actually the data point that we want.  Can we exploit some consistancy here?  Let's first just look at what this split does across all the download lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Downloads:', '9', '(2017-08-30', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '10', '(2017-09-08', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '6', '(2017-09-06', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '47', '(2017-06-15', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '99', '(2016-12-18', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '3', '(2017-12-12', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '30', '(2016-12-12', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '42', '(2016-12-12', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '93', '(2016-12-12', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '31', '(2016-12-12', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '50', '(2016-12-12', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '12', '(2017-08-11', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '0', '(2017-08-21', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '99', '(2017-07-29', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '931', '(2017-06-28', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '28', '(2017-06-16', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '26', '(2017-06-16', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '28', '(2017-06-16', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '40', '(2017-06-01', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '68', '(2017-06-01', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '18', '(2017-05-01', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '41', '(2017-05-31', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '516', '(2016-06-23', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '72', '(2017-05-22', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '82', '(2017-03-07', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '37', '(2017-03-07', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '1634', '(2016-05-19', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '99', '(2016-06-23', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '110', '(2016-05-26', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '312', '(2017-03-08', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '132', '(2017-03-02', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '78', '(2017-02-28', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '46', '(2017-02-23', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '140', '(2017-02-21', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '84', '(2017-02-21', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '424', '(2017-01-06', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '269', '(2016-12-20', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '212', '(2016-12-19', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '237', '(2016-12-14', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '98', '(2016-12-14', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '207', '(2016-12-14', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '193', '(2016-12-14', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '200', '(2016-12-14', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '403', '(2016-12-14', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '283', '(2016-12-14', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '336', '(2016-12-13', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '55', '(2016-12-02', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '69', '(2016-11-30', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '163', '(2016-11-28', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '132', '(2016-06-06', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '51', '(2016-08-16', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '70', '(2016-08-18', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '250', '(2016-08-02', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '913', '(2016-07-22', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '130', '(2016-05-16', 'to', '2017-09-13', ')']\n",
      "['Downloads:', '118', '(2016-06-23', 'to', '2017-09-13', ')']\n"
     ]
    }
   ],
   "source": [
    "for record in full_text_fixed_split:\n",
    "    record_split = record.split('\\n')\n",
    "    dowload_line = record_split[-1]\n",
    "    print(dowload_line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection seems to indicate that there is a consistancy that we want.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
